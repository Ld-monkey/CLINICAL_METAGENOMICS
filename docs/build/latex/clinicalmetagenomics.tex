%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,french]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Sonny]{fncychap}
\ChNameVar{\Large\normalfont\sffamily}
\ChTitleVar{\Large\normalfont\sffamily}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsfrench{\renewcommand{\contentsname}{Shell scripts:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{0}



\title{CLINICAL METAGENOMICS}
\date{juin 24, 2020}
\release{0.0.1}
\author{Zygnematophyce}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Version}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{Introduction :}
\label{\detokenize{index:introduction}}
Le but de cette documentation est d’éclaissir les zones d’ombres et de s’imprégner le plus rapidement possible des différents scripts bash et python que constitue ce projet.

Dans cette documentation vous trouvez la description, l’utilisation, les paramètres ou encore les fichiers de sorties de chaques programmes.


\section{Créer les bases de données personnalisées avec Kraken 2}
\label{\detokenize{bash/create_kraken_database.sh:creer-les-bases-de-donnees-personnalisees-avec-kraken-2}}\label{\detokenize{bash/create_kraken_database.sh::doc}}
Le programme shell qui permet de créer une base de données kraken 2 personnalisées est :

\begin{sphinxadmonition}{hint}{Indication:}
create\_kraken\_database.sh
\end{sphinxadmonition}


\subsection{Localisation}
\label{\detokenize{bash/create_kraken_database.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── bash
 │   ├── create\PYGZus{}kraken\PYGZus{}database.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{bash/create_kraken_database.sh:description}}
Créer une base de donnée personnalisée avec l’outil Kraken 2. Nous pouvons ajouter des séquences spécifiques ou encore ajouter ultérieurement des séquences dans la base de donnée.


\subsection{Les paramètres d’entrés}
\label{\detokenize{bash/create_kraken_database.sh:les-parametres-d-entres}}\begin{quote}
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}ref}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input) Le chemin du fichier contenant les séquences au format .fna
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}database}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input) Le chemin de la base de donnée pour la créer ou l’actualiser.
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}threads}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input) Le nombre de puissance (threads) pour créer la base de donnée plus rapidement.
\end{quote}


\subsection{Exemple d’execution}
\label{\detokenize{bash/create_kraken_database.sh:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
create\PYGZus{}kraken\PYGZus{}database.sh \PYGZhy{}ref /path/FDA\PYGZus{}ARGOS \PYGZhy{}database /output\PYGZus{}FDA\PYGZus{}ARGOS \PYGZhy{}thread \PYG{l+m}{1}
\end{sphinxVerbatim}


\subsection{Les fichiers de sorties}
\label{\detokenize{bash/create_kraken_database.sh:les-fichiers-de-sorties}}
Les fichiers de sorties sont les suivants : hash.k2d, opts.k2d, taxo.k2d.
\begin{itemize}
\item {} 
hash.k2d: contient le minimiseur pour les mappages de taxons.

\item {} 
opts.k2d: contient des informations sur les options utilisées pour créer la base de données.

\item {} 
taxo.k2d: contient les informations de taxonomie utilisées pour créer la base de données.

\end{itemize}


\section{Classifier les séquences}
\label{\detokenize{bash/classify_set_sequences.sh:classifier-les-sequences}}\label{\detokenize{bash/classify_set_sequences.sh::doc}}
Le programme shell qui permet d’executer la classification d’organismes s’appelle :

\begin{sphinxadmonition}{hint}{Indication:}
classify\_set\_sequences.sh
\end{sphinxadmonition}


\subsection{Localisation}
\label{\detokenize{bash/classify_set_sequences.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── bash
 │   ├── classify\PYGZus{}set\PYGZus{}sequences.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{bash/classify_set_sequences.sh:description}}
Détermine les organismes présent dans un échantillon ou reads. L’échantillon possède la totalité des séquences nucléotidique avec un format fastq.

\begin{sphinxadmonition}{warning}{Avertissement:}
Les séquences par paires doivent s’appeler *R1*.fastq
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
* L’étoile indique que n’importe quelle chaine de caractère peut se positionner avant ou après.
\end{sphinxadmonition}


\subsection{Les paramètres d’entrés}
\label{\detokenize{bash/classify_set_sequences.sh:les-parametres-d-entres}}\begin{quote}
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_reads}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input)  Le chemin du dossier l’échantillon contenant les reads.                 *FILE: sequences.fastq
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_db}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input)  Le chemin du dossier qui contient la base de donnée.
*DIR: input\_database avec hash.k2d + opts.k2d + taxo.k2d.
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_output}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Output) Le nom du dossier de sortie.                                            *DIR: output\_database
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}threads}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input)  Le nombre de puissance (threads) pour classer plus vite.                *INT: e.g 1
\end{quote}


\subsection{Exemple d’execution}
\label{\detokenize{bash/classify_set_sequences.sh:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
classify\PYGZus{}set\PYGZus{}sequences.sh \PYGZhy{}path\PYGZus{}reads all\PYGZus{}reads\PYGZus{}from\PYGZus{}sample \PYGZhy{}path\PYGZus{}db database\PYGZus{}FDA\PYGZus{}ARGOS \PYGZhy{}path\PYGZus{}output output\PYGZus{}result \PYGZhy{}threads \PYG{l+m}{1}
\end{sphinxVerbatim}


\subsection{Les fichiers de sorties}
\label{\detokenize{bash/classify_set_sequences.sh:les-fichiers-de-sorties}}
Les fichiers de sorties sont les suivants : *.clseqs\_*.fastq, *.unclseq\_*.fq, *.output.txt, *.report.txt .
\begin{itemize}
\item {} 
*.clseqs.fastq : Tous les reads classés.

\item {} 
*.unclseqs.fastq : Tous les reads non\sphinxhyphen{}classés.

\item {} 
*.output.txt : ?.

\item {} 
*.report.txt : La phylogénie des organismes qui sont classés avec succès.

\end{itemize}


\section{Création d’une base de donnée pour blast sans les séquences de faibles compléxités}
\label{\detokenize{bash/create_blast_database_without_low_complexity.sh:creation-d-une-base-de-donnee-pour-blast-sans-les-sequences-de-faibles-complexites}}\label{\detokenize{bash/create_blast_database_without_low_complexity.sh::doc}}
Le programme shell qui permet de créer un base de donnée spécific au analyse d’alignement de blast.

\begin{sphinxadmonition}{hint}{Indication:}
create\_blast\_database\_without\_low\_complexity.sh
\end{sphinxadmonition}


\subsection{Localisation}
\label{\detokenize{bash/create_blast_database_without_low_complexity.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── bash
 │   ├── create\PYGZus{}blast\PYGZus{}database\PYGZus{}without\PYGZus{}low\PYGZus{}complexity.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{bash/create_blast_database_without_low_complexity.sh:description}}
Création d’une base de donnée qui peut être utilisée par le logiciel d’alignement de séquences blast avec makeblastdb.

\begin{sphinxadmonition}{note}{Note:}
Les séquences brutes téléchargées avec ncbi ou avec le script python get\_database\_from\_accession\_list.py. Le script d’automatise la création d’un seul fichier qui rassemble toutes les séquences au format .fna .
\end{sphinxadmonition}


\subsection{Les paramètres d’entrés}
\label{\detokenize{bash/create_blast_database_without_low_complexity.sh:les-parametres-d-entres}}\begin{quote}
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_seqs}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input) Le chemin du dossier contenant toutes les séquences pour permettre la création d’une base de donnée.*DIR: all\_sequences
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}output\_fasta}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Output) Le nom du fichier de sortie qui contient toutes les séquences.*FILE: output\_sequences
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}name\_db}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input/Output) Le nom de la database.*DIR: 16S\_database
\end{quote}


\subsection{Exemple d’execution}
\label{\detokenize{bash/create_blast_database_without_low_complexity.sh:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
create\PYGZus{}blast\PYGZus{}database\PYGZus{}without\PYGZus{}low\PYGZus{}complexity.sh \PYGZhy{}path\PYGZus{}seqs test\PYGZus{}database\PYGZus{}blast/ \PYGZhy{}output\PYGZus{}fasta output\PYGZus{}multi\PYGZus{}fasta \PYGZhy{}name\PYGZus{}db database\PYGZus{}test
\end{sphinxVerbatim}


\subsection{Les fichiers de sorties}
\label{\detokenize{bash/create_blast_database_without_low_complexity.sh:les-fichiers-de-sorties}}\begin{itemize}
\item {} 
Le dossier DUSTMASKER\_* va être créé s’il n’est pas encore créé dans la base de donnée. Ce dossier contient le ficher dustmasker.asnb qui permet d’enlever les séquences à faibles complexités.

\item {} 
Le dossier MAKEBLAST\_* va créer la base de donnée.

\item {} 
Le fichier README.txt contient un récapitulatif de notre base de donnée.

\end{itemize}


\section{Analyse des séquences ou reads avec l’algorithme de Blast}
\label{\detokenize{bash/launch_blast_analyse.sh:analyse-des-sequences-ou-reads-avec-l-algorithme-de-blast}}\label{\detokenize{bash/launch_blast_analyse.sh::doc}}
Le programme shell permet de réaliser un alignement de séquences avec l’algorithme de blast. Les séquences ou reads sont alignés sur une base de donnée.

\begin{sphinxadmonition}{warning}{Avertissement:}
Il faut créer une base de donnée spécifique pour l’analyse avec l’algorithme de blast.
\end{sphinxadmonition}

\begin{sphinxadmonition}{hint}{Indication:}
launch\_blast\_analyse.sh
\end{sphinxadmonition}


\subsection{Localisation}
\label{\detokenize{bash/launch_blast_analyse.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── bash
 │   ├── launch\PYGZus{}blast\PYGZus{}analyse.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{bash/launch_blast_analyse.sh:description}}
A partir d’un jeu de séquences ou reads et dépendant de la base de donnée donnée en argument le script permet de réaliser un alignement de séquence avec l’algorihtme de blast.

\begin{sphinxadmonition}{note}{Note:}
Pour plus d’information sur les paramètres utilisés avec blastn aller sur le lien suivant : \sphinxurl{http://nebc.nerc.ac.uk/bioinformatics/documentation/blast+/user\_manual.pdf}
\end{sphinxadmonition}


\subsection{Exemple d’execution}
\label{\detokenize{bash/launch_blast_analyse.sh:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
launch\PYGZus{}blast\PYGZus{}analyse.sh \PYGZhy{}path\PYGZus{}reads sample\PYGZus{}reads \PYGZhy{}path\PYGZus{}db FDA\PYGZus{}ARGOS\PYGZus{}db \PYGZhy{}path\PYGZus{}result blast\PYGZus{}metaplan\PYGZus{}output
\end{sphinxVerbatim}


\subsection{Les paramètres d’entrés}
\label{\detokenize{bash/launch_blast_analyse.sh:les-parametres-d-entres}}\begin{quote}
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_reads}] \leavevmode
\end{description}\end{quote}

\end{itemize}
\begin{quote}

(Input) Le chemin du dossier avec toutes les séquences ou reads. \sphinxstyleemphasis{DIR: sequences}.fna
\end{quote}
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_db}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input) Le chemin du dossier avec la base de donnée spécifique a l’algorithme de blast.
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_results}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Output) Le chemin du dossier de sortie pour les résultats.*DIR: blast\_result
\end{quote}


\subsection{Les fichiers de sorties}
\label{\detokenize{bash/launch_blast_analyse.sh:les-fichiers-de-sorties}}\begin{itemize}
\item {} 
Les fichiers avec l’extention *.blast.txt résultat de l’algorithme de blast.

\end{itemize}


\section{Lancer le préprocess ou nettoyage des séquences ou reads}
\label{\detokenize{bash/launch_preprocess.sh:lancer-le-preprocess-ou-nettoyage-des-sequences-ou-reads}}\label{\detokenize{bash/launch_preprocess.sh::doc}}
Le programme shell permet de lancer l’action de preprocess dans le pipeline. Autrement dit le script nettoye en supprimant les reads ou séquences de mauvaises qualités ainsi que les reads en duplicatas.

\begin{sphinxadmonition}{hint}{Indication:}
launch\_preprocess.sh
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── bash
 │   ├── launch\PYGZus{}preprocess.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{bash/launch_preprocess.sh:description}}
Le script nettoie en supprimant les duplicatas et la mauvaise qualité des reads.

\begin{sphinxadmonition}{warning}{Avertissement:}
A besoin des outils comme BBMap (clumpify.sh) et  Trimmomatic pour fonctionner.
\end{sphinxadmonition}


\subsection{Les paramètres d’entrés}
\label{\detokenize{bash/launch_preprocess.sh:les-parametres-d-entres}}\begin{quote}
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_reads}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input)  Le chemin dossier avec l’ensemble des reads. *DIR: reads\_sample
\end{quote}


\subsection{Exemple d’execution}
\label{\detokenize{bash/launch_preprocess.sh:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
launch\PYGZus{}preprocess.sh \PYGZhy{}path\PYGZus{}reads all\PYGZus{}reads\PYGZus{}from\PYGZus{}sample
\end{sphinxVerbatim}


\subsection{Les fichiers de sorties}
\label{\detokenize{bash/launch_preprocess.sh:les-fichiers-de-sorties}}

\section{Récupérer les reads d’intérêts}
\label{\detokenize{bash/recover_reads.sh:recuperer-les-reads-d-interets}}\label{\detokenize{bash/recover_reads.sh::doc}}

\section{Comparer les identifiants taxonomiques entre Kraken et Blast}
\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh:comparer-les-identifiants-taxonomiques-entre-kraken-et-blast}}\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh::doc}}
Le programme shell qui permet de récupérer les identifiant du même genre s’appelle :

\begin{sphinxadmonition}{hint}{Indication:}
find\_same\_id\_kraken\_blast\_bacteria.sh
\end{sphinxadmonition}


\subsection{Localisation}
\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── bash
 │   ├── find\PYGZus{}same\PYGZus{}id\PYGZus{}kraken\PYGZus{}blast\PYGZus{}bacteria.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh:description}}
Pour chaque échantillons et pour chaque reads alignés le programme :
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
compare les identifiants taxonomiques Blast et Kraken et ne conserve que ceux qui sont du même genre,

\item {} 
compte le nombre de reads pour chaque espèce,

\item {} 
dessine la carte de couverture des viruses,

\item {} 
et récupère les noms des espèces pour remplacer les ID taxonomiques.

\end{enumerate}

\begin{sphinxadmonition}{warning}{Avertissement:}
Il peut être important d’utiliser l’environnement conda « metagenomic\_env » pour le bon déroulement des scripts.
\end{sphinxadmonition}

\begin{sphinxadmonition}{warning}{Avertissement:}
Le programme dépend de plusieurs sous programme qui sont :
sort\_blasted\_seq.py
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
Les programmes python se trouvent dans le dossier src/python/ .
\end{sphinxadmonition}


\subsection{Les paramètres d’entrés}
\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh:les-parametres-d-entres}}\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_taxo}] \leavevmode
\end{description}\end{quote}

(Input)  The path of folder with Bacteria or Viruses or (Fongi) folders          *DIR: input\_bacteria\_folder

\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_blast}] \leavevmode
\end{description}\end{quote}

(Input)  The folder of the blast results containing .blast.txt.                  *DIR: input\_results\_blast

\item {} \begin{quote}\begin{description}
\item[{\sphinxhyphen{}path\_ncbi}] \leavevmode
\end{description}\end{quote}

(Input)  The folder of ncbi taxonomy containing .taxa.sqlite .                   *DIR: input\_blast\_taxa\_db

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
A noter que si le paramètre \sphinxhyphen{}path\_ncbi n’est pas précisé le programme va par défault choisir le chemin suivant: \textasciitilde{}/.etetoolkit/ pour trouver la base de données taxa.sqlite. Si aucune base de donnée n’est retrouvée c’est peut\sphinxhyphen{}être parce que la base de donnée taxonomique de ncbi n’a pas été télécharger. Nous pouvons télécharger cette base de donnée grace au programme download\_ete3\_ncbi\_taxa\_db.sh (dans le dossier src/download/).
\end{sphinxadmonition}


\subsection{Exemple d’execution}
\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
./find\PYGZus{}same\PYGZus{}id\PYGZus{}kraken\PYGZus{}blast\PYGZus{}bacteria.sh \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}path\PYGZus{}taxo ../../results/test/bacteria\PYGZus{}reads\PYGZus{}clean\PYGZus{}fda\PYGZus{}refseq\PYGZus{}human\PYGZus{}viral\PYGZus{}07\PYGZus{}05\PYGZus{}2020/ \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}path\PYGZus{}blast ../../results/test/bacteria\PYGZus{}metaphlan\PYGZus{}blast\PYGZus{}clean\PYGZus{}fda\PYGZus{}refseq\PYGZus{}human\PYGZus{}viral\PYGZus{}07\PYGZus{}05\PYGZus{}2020/ \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}path\PYGZus{}ncbi ../../data/databases/ete3\PYGZus{}ncbi\PYGZus{}taxanomy\PYGZus{}database\PYGZus{}05\PYGZus{}05\PYGZus{}2020/
\end{sphinxVerbatim}


\subsection{Les fichiers de sorties pour la comparaison d’identifiants taxonomiques}
\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh:les-fichiers-de-sorties-pour-la-comparaison-d-identifiants-taxonomiques}}
\begin{sphinxadmonition}{note}{Note:}
Dans le dossier ou se trouve les résultats des blasts, un dossier pour chaque fichier blast sera créés. Ce dossier comprend les identifiants taxonomiques qui sont conservés. Les identifiants taxonomiques qui sont conservées entre Blast et Kraken sont les identifiants du même genre.
\end{sphinxadmonition}

Les fichiers de sortie sont :
\begin{itemize}
\item {} 
*\_conserved.txt : Les identifiants taxonomiques conservés.

\item {} 
*\_notconserved.txt : Les identifiants taxonomiques qui ne sont pas conservés.

\end{itemize}


\subsubsection{Exemple d’un fichier avec des identifiants conversés :}
\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh:exemple-d-un-fichier-avec-des-identifiants-converses}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
NB552188:4:H353CBGXC:4:22605:9229:16747 gi\PYG{p}{|}\PYG{l+m}{422547321}\PYG{p}{|}ref\PYG{p}{|}NZ\PYGZus{}GL383459.1\PYG{p}{|}:130129\PYGZhy{}130737   \PYG{l+m}{356}     \PYG{l+m}{446}     5e\PYGZhy{}41   \PYG{l+m}{169}     \PYG{l+m}{609}     \PYG{l+m}{765102}  \PYG{l+m}{1747}    \PYG{l+m}{1}
NB552188:4:H353CBGXC:2:22205:2911:15651 gi\PYG{p}{|}\PYG{l+m}{490241673}\PYG{p}{|}ref\PYG{p}{|}NZ\PYGZus{}CALM01000137.1\PYG{p}{|}:c5103\PYGZhy{}4639  \PYG{l+m}{1}       \PYG{l+m}{85}      1e\PYGZhy{}30   \PYG{l+m}{135}     \PYG{l+m}{465}     \PYG{l+m}{1118157} \PYG{l+m}{40324}   \PYG{l+m}{1}
\end{sphinxVerbatim}


\subsection{A suivre …}
\label{\detokenize{bash/find_same_id_kraken_blast_bacteria.sh:a-suivre}}

\section{Récupérer les identifiants taxonomiques du même genre entre Kraken et Blast}
\label{\detokenize{python/sort_blasted_seq.py:recuperer-les-identifiants-taxonomiques-du-meme-genre-entre-kraken-et-blast}}\label{\detokenize{python/sort_blasted_seq.py::doc}}
Recover sequence with conserved classification between Kraken2 and BLAST. This program allow to separate the sequences : those which have a similar taxonomy at the genus level are gathered in the file « conserved.txt » (output).


\subsection{Les paramètres d’entrés}
\label{\detokenize{python/sort_blasted_seq.py:les-parametres-d-entres}}
Les 3 paramètres sont :
\begin{itemize}
\item {} 
\sphinxhyphen{}i : The blast file input e.g *.blast.txt .

\item {} 
\sphinxhyphen{}o : The output file for e.g *\_conserved.txt

\item {} 
\sphinxhyphen{}n : The localization of NCBI taxa database.

\end{itemize}


\subsection{Exemple d’execution}
\label{\detokenize{python/sort_blasted_seq.py:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
python ../python/sort\PYGZus{}blasted\PYGZus{}seq.py \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}i \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{BLAST\PYGZus{}FOLDER}\PYG{l+s+si}{\PYGZcb{}}\PYG{n+nv}{\PYGZdl{}EACH\PYGZus{}BLAST\PYGZus{}FILE} \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}o \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{BASENAME\PYGZus{}FILE}\PYG{l+s+si}{\PYGZcb{}}conserved.txt \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}n \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PATH\PYGZus{}NCBI\PYGZus{}TAXA}\PYG{l+s+si}{\PYGZcb{}}taxa.sqlite
\end{sphinxVerbatim}


\section{Création d’un base de donnée 16S avec le cluster}
\label{\detokenize{cluster/cluster_create_16S_database.sh:creation-d-un-base-de-donnee-16s-avec-le-cluster}}\label{\detokenize{cluster/cluster_create_16S_database.sh::doc}}
Le programme destiné au cluster pour créer une base de donnée 16S est :

\begin{sphinxadmonition}{hint}{Indication:}
cluster\_create\_16S\_database.sh
\end{sphinxadmonition}


\subsection{Localisation}
\label{\detokenize{cluster/cluster_create_16S_database.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── cluster
 │   └── cluster\PYGZus{}create\PYGZus{}16S\PYGZus{}database.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{cluster/cluster_create_16S_database.sh:description}}
Automatise la création d’une base de donnée 16S sur un cluster. Il récupère toutes les séquences et les stocke dans le format .fastq .

\begin{sphinxadmonition}{note}{Note:}
Le script ne fait que appeler le programme python get\_database\_from\_accession\_list.py. L’avantage du script shell est qu’il est adapté à l’utilisation dans un cluster. Pour plus d’information sur le programme python voir \sphinxurl{https://github.com/Zygnematophyce/FASTQ\_FROM\_ACCESSION\_LIST} .
\end{sphinxadmonition}

\begin{sphinxadmonition}{warning}{Avertissement:}
Utilise un environnement conda.
\end{sphinxadmonition}


\subsection{Les paramètres d’entrés}
\label{\detokenize{cluster/cluster_create_16S_database.sh:les-parametres-d-entres}}\begin{quote}
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{ACCESSION\_LIST\_FILE}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Input) Le chemin du fichier de la liste d’accession (.seq)
\begin{itemize}
\item {} \begin{quote}\begin{description}
\item[{NAME\_OUTPUT\_FASTQ}] \leavevmode
\end{description}\end{quote}

\end{itemize}

(Output) Le nom du fichier de sortie en format .fastq .
\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
qsub cluster\PYGZus{}create\PYGZus{}16S\PYGZus{}database.sh accession\PYGZus{}list\PYGZus{}16S\PYGZus{}ncbi.seq 16S\PYGZus{}output\PYGZus{}database.fastq
\end{sphinxVerbatim}


\subsection{Le fichier de sortie}
\label{\detokenize{cluster/cluster_create_16S_database.sh:le-fichier-de-sortie}}
Le programme sort l’ensemble des séquences d’intérets dans le format .fastq.


\section{Création de plusieurs bases de données et classification}
\label{\detokenize{cluster/cluster_create_2_custom_databases_and_classify.sh:creation-de-plusieurs-bases-de-donnees-et-classification}}\label{\detokenize{cluster/cluster_create_2_custom_databases_and_classify.sh::doc}}
Le programme destiné au cluster pour créer plusieurs bases de données est :

\begin{sphinxadmonition}{hint}{Indication:}
cluster\_create\_2\_custom\_databases\_and\_classify.sh
\end{sphinxadmonition}


\subsection{Localisation}
\label{\detokenize{cluster/cluster_create_2_custom_databases_and_classify.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── cluster
 │   └── cluster\PYGZus{}create\PYGZus{}2\PYGZus{}custom\PYGZus{}databases\PYGZus{}and\PYGZus{}classify.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{cluster/cluster_create_2_custom_databases_and_classify.sh:description}}
Automatise la création de plusieurs bases de données différentes et execute la classification de reads.

Les bases de données créées dans ce script sont les suivantes :
\begin{itemize}
\item {} 
FDA\sphinxhyphen{}ARGOS database

\item {} 
FDA\sphinxhyphen{}ARGOS + RefSeqHuman + Virus database

\end{itemize}

La classification des reads se fait sur les bases de données suivantes :
\begin{itemize}
\item {} 
FDA\sphinxhyphen{}ARGOS,

\item {} 
FDA database + RefSeqHuman + Virus,

\item {} 
RefSeq,

\item {} 
FDA\sphinxhyphen{}ARGOS avec prepocess et dust,

\item {} 
FDA\sphinxhyphen{}ARGOS + RefSeqHuman + Virus preprocess.

\end{itemize}

Pour comprendre les scripts du preprocess et de dust aller à la rebrique suivante : .

\begin{sphinxadmonition}{warning}{Avertissement:}
La variable PATH est incompatible avec d’autre environnement. Trouver un moyen avec un environnement conda.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
Le module kraken 2 doit être chargé.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
L’extention des échantillons sont transformés automatiquement en format .fastq .
\end{sphinxadmonition}


\subsection{Les paramètres d’entrés}
\label{\detokenize{cluster/cluster_create_2_custom_databases_and_classify.sh:les-parametres-d-entres}}
\begin{sphinxadmonition}{note}{Note:}
Aucun
\end{sphinxadmonition}


\subsection{Le fichier de sortie}
\label{\detokenize{cluster/cluster_create_2_custom_databases_and_classify.sh:le-fichier-de-sortie}}
Le programme sort les fichiers des bases de données créées et les classifications sur l’échantillon pour chaque bases de données.


\section{Alignement des séquences ou reads avec l’algorithme de blast}
\label{\detokenize{cluster/cluster_launch_blast.sh:alignement-des-sequences-ou-reads-avec-l-algorithme-de-blast}}\label{\detokenize{cluster/cluster_launch_blast.sh::doc}}
Le programme destiné au cluster aide l’analyse des séquences ou reads avec une base de donnée et l’algorithme de blast.

\begin{sphinxadmonition}{hint}{Indication:}
cluster\_launch\_blast.sh
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── cluster
 │   └── cluster\PYGZus{}launch\PYGZus{}blast.sh
\end{sphinxVerbatim}


\subsection{Description}
\label{\detokenize{cluster/cluster_launch_blast.sh:description}}
Le script shell adapté au cluster pour automatiser l’analyse par blast.

\begin{sphinxadmonition}{warning}{Avertissement:}
A besoin de l’environnement conda EnvAntL et du module bastplus pour fonctionner correctement.
\end{sphinxadmonition}


\section{Nettoyage des séquences ou reads avec l’action de preprocess}
\label{\detokenize{cluster/cluster_launch_preprocess.sh:nettoyage-des-sequences-ou-reads-avec-l-action-de-preprocess}}\label{\detokenize{cluster/cluster_launch_preprocess.sh::doc}}
Le programme destiné au cluster aide à automatiser le nettoyage des séquences ou reads en supprimant les duplicatas et les reads de mauvaises qualités.

\begin{sphinxadmonition}{hint}{Indication:}
cluster\_launch\_preprocess.sh
\end{sphinxadmonition}

\begin{sphinxadmonition}{warning}{Avertissement:}
A besoin de l’environnement conda EnvAntL pour fonctionner correctement.
\end{sphinxadmonition}


\section{Récupérer l’ID taxonomique et les reads d’intérêts}
\label{\detokenize{cluster/cluster_launch_get_id_and_reads.sh:recuperer-l-id-taxonomique-et-les-reads-d-interets}}\label{\detokenize{cluster/cluster_launch_get_id_and_reads.sh::doc}}

\section{Télécharger les séquences des espèces virales et bactériennes}
\label{\detokenize{download/download_refseq_species_sequences.sh:telecharger-les-sequences-des-especes-virales-et-bacteriennes}}\label{\detokenize{download/download_refseq_species_sequences.sh::doc}}
Dans ce projet nous avons créé des scripts en bash qui automatise le téléchargement des bases de données. Ces bases de données sont spécifiques à notre études.

Les scripts qui permettent d’automatiser le téléchargement et le traitement des données sont :

\begin{sphinxadmonition}{hint}{Indication:}
download\_refseq\_viral\_sequences.sh

download\_refseq\_bacterial\_sequences.sh
\end{sphinxadmonition}

\begin{sphinxadmonition}{warning}{Avertissement:}
Il peut être important d’utiliser l’environnement conda « metagenomic\_env » pour le bon déroulement des scripts.
\end{sphinxadmonition}


\subsection{Les bases de données}
\label{\detokenize{download/download_refseq_species_sequences.sh:les-bases-de-donnees}}
Les bases de données sont :
\begin{itemize}
\item {} 
Les séquences nucléotidiques de toutes les espèces virales de refseq.

\item {} 
Les séquences nucléotidiques de toutles les espèces bactériennes de refseq.

\end{itemize}


\subsection{Localisation}
\label{\detokenize{download/download_refseq_species_sequences.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── download
 │   ├── download\PYGZus{}refseq\PYGZus{}viral\PYGZus{}sequences.sh
     ├── download\PYGZus{}refseq\PYGZus{}bacterial\PYGZus{}sequences.sh
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Avertissement:}
Les programmes ci\sphinxhyphen{}dessus ont besoin du script en perl « makemap.pl » pour fonctionner. Le programme « makemap.pl » permet d’extraire les séquences fasta et leurs références taxonomiques.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
Le programme va stocker le téléchargement dans le répertoire suivant :
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── data
 ├── raw\PYGZus{}sequences
 │   ├── bacteria\PYGZus{}sequences\PYGZus{}from\PYGZus{}refseq\PYGZus{}01\PYGZus{}05\PYGZus{}2020
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
A noter que les scripts génèrent automatiquement un dossier avec la date.
\end{sphinxadmonition}


\subsection{Exemple d’execution}
\label{\detokenize{download/download_refseq_species_sequences.sh:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
./download\PYGZus{}refseq\PYGZus{}viral\PYGZus{}sequences.sh
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
./download\PYGZus{}refseq\PYGZus{}bacterial\PYGZus{}sequences.sh
\end{sphinxVerbatim}


\subsection{Les fichiers d’entrées}
\label{\detokenize{download/download_refseq_species_sequences.sh:les-fichiers-d-entrees}}
Les fichiers d’entrées sont les suivants :
\begin{itemize}
\item {} 
*.gbff.gz : Le format génomics de genbank dans ncbi.

\end{itemize}


\subsection{Les fichiers de sorties}
\label{\detokenize{download/download_refseq_species_sequences.sh:les-fichiers-de-sorties}}
Les fichiers de sorties sont les suivants :
\begin{itemize}
\item {} 
*.fasta : L’extraction des séquences fasta.

\item {} 
all\_genomic\_\$specie\_sequences.fasta : Le regroupement dans un seul fichier de toutes les séquences fasta.

\item {} 
*.map : L’extraction des références taxonomiques.

\item {} 
\$specie\_map.complete : Le regroupement dans un seul fichier de toutes les références taxonomiques.

\end{itemize}


\section{Télécharger la taxonomie de ncbi avec ete3toolkit}
\label{\detokenize{download/download_ete3_ncbi_taxonomy_database.sh:telecharger-la-taxonomie-de-ncbi-avec-ete3toolkit}}\label{\detokenize{download/download_ete3_ncbi_taxonomy_database.sh::doc}}
Le script shell suivant permet d’automatiser le téléchargement de la taxonomie nécessaire pour la librairie python ete3.

\begin{sphinxadmonition}{hint}{Indication:}
download\_ete3\_ncbi\_taxa\_db.sh
\end{sphinxadmonition}

Cette base de donnée taxonomique peut\sphinxhyphen{}être importante dans certain programme. En autre le chemin de cette base de données est un paramètre (\sphinxhyphen{}path\_ncbi) du programme shell find\_same\_id\_kraken\_blast.sh .

\begin{sphinxadmonition}{warning}{Avertissement:}
Il peut être important d’utiliser l’environnement conda « metagenomic\_env » pour le bon déroulement des scripts.
\end{sphinxadmonition}

\begin{sphinxadmonition}{warning}{Avertissement:}
Ce programme ci\sphinxhyphen{}dessus dépend du programme python appelé get\_ete3\_ncbi\_taxa\_db.py. Le programme python se trouve dans le dossier src/python/ .
\end{sphinxadmonition}


\subsection{Les bases de données}
\label{\detokenize{download/download_ete3_ncbi_taxonomy_database.sh:les-bases-de-donnees}}
Les bases de données générées sont :
\begin{itemize}
\item {} 
taxa.sqlite

\item {} 
taxa.sqlite.traverse.pkl

\end{itemize}


\subsection{Localisation}
\label{\detokenize{download/download_ete3_ncbi_taxonomy_database.sh:localisation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── src
 ├── download
 │   ├── download\PYGZus{}ete3\PYGZus{}ncbi\PYGZus{}taxa\PYGZus{}db.sh
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
Le programme va stocker la base de donnée dans le répertoire suivant :
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
└── data
 ├── databases
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
A noter que les scripts génèrent automatiquement un dossier avec la date.
\end{sphinxadmonition}


\subsection{Exemple d’execution}
\label{\detokenize{download/download_ete3_ncbi_taxonomy_database.sh:exemple-d-execution}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
./download\PYGZus{}ete3\PYGZus{}ncbi\PYGZus{}taxa\PYGZus{}db.sh
\end{sphinxVerbatim}


\section{Environnement Conda}
\label{\detokenize{conda/conda_environnement:environnement-conda}}\label{\detokenize{conda/conda_environnement::doc}}
\begin{sphinxadmonition}{warning}{Avertissement:}
Si le message d’erreur apparait CommandNotFoundError: Your shell has not been properly configured to use “conda activate”.
To initialize your shell, run
\$ conda init \textless{}SHELL\_NAME\textgreater{}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
Pour résoudre le problème sur les distributions Linux executer le code suivant dans un terminal ce qui va exporter les variables de conda dans votre shell (\textasciitilde{}/.bashrc). Ensuite ouvrir une nouvelle fenêtre shell.
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{echo} \PYGZhy{}e \PYG{l+s+s2}{\PYGZdq{}export \PYGZhy{}f conda\PYGZbs{}nexport \PYGZhy{}f \PYGZus{}\PYGZus{}conda\PYGZus{}activate\PYGZbs{}nexport \PYGZhy{}f \PYGZus{}\PYGZus{}conda\PYGZus{}reactivate\PYGZbs{}nexport \PYGZhy{}f \PYGZus{}\PYGZus{}conda\PYGZus{}hashr\PYGZbs{}nexport \PYGZhy{}f \PYGZus{}\PYGZus{}add\PYGZus{}sys\PYGZus{}prefix\PYGZus{}to\PYGZus{}path\PYGZdq{}} \PYGZgt{}\PYGZgt{} \PYGZti{}/.bashrc
\end{sphinxVerbatim}

Pour créer un environnement conda a partir du fichier yaml (metagenomic\_env.yml) :

\begin{sphinxVerbatim}[commandchars=\\\{\}]
conda env create \PYGZhy{}f metagenomic\PYGZus{}env.yml
\end{sphinxVerbatim}

Pour activer l’environnement conda :

\begin{sphinxVerbatim}[commandchars=\\\{\}]
conda active metagenomic\PYGZus{}env
\end{sphinxVerbatim}

Pour désactiver l’environnement conda :

\begin{sphinxVerbatim}[commandchars=\\\{\}]
conda deactivate
\end{sphinxVerbatim}

Pour supprimer l’environnement :

\begin{sphinxVerbatim}[commandchars=\\\{\}]
conda env remove \PYGZhy{}n metagenomic\PYGZus{}env
\end{sphinxVerbatim}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}